{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T19:56:34.279192Z","iopub.execute_input":"2025-04-03T19:56:34.279443Z","iopub.status.idle":"2025-04-03T19:56:39.750021Z","shell.execute_reply.started":"2025-04-03T19:56:34.279410Z","shell.execute_reply":"2025-04-03T19:56:39.748947Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2025.1.31)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.3.0)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T20:04:16.324176Z","iopub.execute_input":"2025-04-03T20:04:16.324506Z","iopub.status.idle":"2025-04-03T20:04:37.405997Z","shell.execute_reply.started":"2025-04-03T20:04:16.324483Z","shell.execute_reply":"2025-04-03T20:04:37.405142Z"}},"outputs":[{"name":"stdout","text":"Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\nDataset URL: https://www.kaggle.com/datasets/mbornoe/lisa-traffic-light-dataset\nLicense(s): CC-BY-NC-SA-4.0\nDownloading lisa-traffic-light-dataset.zip to /kaggle/working\n100%|███████████████████████████████████████| 4.21G/4.21G [00:19<00:00, 298MB/s]\n100%|███████████████████████████████████████| 4.21G/4.21G [00:19<00:00, 228MB/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile(\"lisa-traffic-light-dataset.zip\", \"r\") as zip_ref:\n    zip_ref.extractall(\"lisa_traffic_light\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T20:04:52.315076Z","iopub.execute_input":"2025-04-03T20:04:52.315396Z","iopub.status.idle":"2025-04-03T20:05:30.663017Z","shell.execute_reply.started":"2025-04-03T20:04:52.315372Z","shell.execute_reply":"2025-04-03T20:05:30.662322Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\n\nprint(os.listdir(\"lisa_traffic_light\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T20:07:04.368676Z","iopub.execute_input":"2025-04-03T20:07:04.369072Z","iopub.status.idle":"2025-04-03T20:07:04.374242Z","shell.execute_reply.started":"2025-04-03T20:07:04.369042Z","shell.execute_reply":"2025-04-03T20:07:04.373325Z"}},"outputs":[{"name":"stdout","text":"['nightTrain', 'sample-dayClip6', 'sample-nightClip1', 'dayTrain', 'Annotations', 'nightSequence1', 'daySequence1', 'nightSequence2', 'daySequence2']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -U ultralytics torch torchvision torchaudio pandas scikit-learn pyyaml tqdm opencv-python-headless Pillow wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T07:35:30.413001Z","iopub.execute_input":"2025-04-04T07:35:30.413739Z","iopub.status.idle":"2025-04-04T07:38:45.432746Z","shell.execute_reply.started":"2025-04-04T07:35:30.413706Z","shell.execute_reply":"2025-04-04T07:38:45.431737Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.101)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nCollecting torch\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nCollecting torchvision\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nCollecting torchaudio\n  Downloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nCollecting scikit-learn\n  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nCollecting opencv-python-headless\n  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nCollecting Pillow\n  Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\nRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nCollecting wandb\n  Downloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.14)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m973.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.6.0-cp310-cp310-manylinux1_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading wandb-0.19.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, wandb, nvidia-cusolver-cu12, torch, torchaudio, torchvision, scikit-learn, opencv-python-headless\n  Attempting uninstall: Pillow\n    Found existing installation: pillow 11.0.0\n    Uninstalling pillow-11.0.0:\n      Successfully uninstalled pillow-11.0.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.19.1\n    Uninstalling wandb-0.19.1:\n      Successfully uninstalled wandb-0.19.1\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.5.1+cu121\n    Uninstalling torchaudio-2.5.1+cu121:\n      Successfully uninstalled torchaudio-2.5.1+cu121\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: opencv-python-headless\n    Found existing installation: opencv-python-headless 4.10.0.84\n    Uninstalling opencv-python-headless-4.10.0.84:\n      Successfully uninstalled opencv-python-headless-4.10.0.84\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-11.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencv-python-headless-4.11.0.86 scikit-learn-1.6.1 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0 triton-3.2.0 wandb-0.19.9\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# --- Installation (only run once) ---\n!pip install ultralytics pandas scikit-learn pyyaml tqdm opencv-python-headless Pillow # Headless OpenCV for Kaggle\n!pip install wandb # For live visualization\n\n# --- Imports ---\nimport os\nimport pandas as pd\nimport yaml\nfrom sklearn.model_selection import train_test_split\nimport shutil\nimport cv2\nfrom tqdm.notebook import tqdm # Use notebook-friendly tqdm\nimport torch\nimport wandb\nimport sys\nimport time\nfrom ultralytics import YOLO\nimport logging\n\n# --- Configure Logging ---\n# Reduce ultralytics logging spam if needed, or keep default for verbosity\n# logging.getLogger('ultralytics').setLevel(logging.WARNING)\n\nprint(\"--- Setup Complete ---\")\n# Verify GPU availability for Ultralytics/PyTorch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\nelse:\n    print(\"WARNING: No CUDA GPUs detected. Training will use CPU.\")\nprint(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:00:01.811164Z","iopub.execute_input":"2025-04-04T10:00:01.811443Z","iopub.status.idle":"2025-04-04T10:00:17.483355Z","shell.execute_reply.started":"2025-04-04T10:00:01.811420Z","shell.execute_reply":"2025-04-04T10:00:17.482600Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.101-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.101-py3-none-any.whl (977 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m977.3/977.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.101 ultralytics-thop-2.0.14\nRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n--- Setup Complete ---\nPyTorch version: 2.5.1+cu121\nCUDA available: True\nNumber of GPUs: 1\n  GPU 0: Tesla P100-PCIE-16GB\n------------------------------\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Dataset Paths (Adjust if your unzip location is different) ---\nBASE_DIR = \"/kaggle/working/\"\nLISA_DATASET_DIR = os.path.join(BASE_DIR, \"lisa_traffic_light\")\nANNOTATIONS_DIR = os.path.join(LISA_DATASET_DIR, \"Annotations\")\n# !! IMPORTANT: Verify this CSV filename exists in the Annotations folder !!\n# Common names: allAnnotations.csv, annotations.csv. Check your folder!\nLISA_CSV_PATH = os.path.join(ANNOTATIONS_DIR, \"allAnnotations.csv\")\n# Base directory where actual image frames are stored (the script will look inside subfolders like daySequence1/frames)\nLISA_IMAGES_BASE_DIR = LISA_DATASET_DIR # Images are relative to this path based on CSV Filename column\n\n# --- Output Paths ---\nYOLO_DATASET_NAME = \"lisa_yolo_format\"\nYOLO_DATASET_DIR = os.path.join(BASE_DIR, YOLO_DATASET_NAME)\nOUTPUT_LABELS_DIR = os.path.join(YOLO_DATASET_DIR, \"raw_labels\") # Temporary location for all converted labels\nTRAIN_IMG_DIR = os.path.join(YOLO_DATASET_DIR, \"images/train\")\nVAL_IMG_DIR = os.path.join(YOLO_DATASET_DIR, \"images/val\")\nTRAIN_LABEL_DIR = os.path.join(YOLO_DATASET_DIR, \"labels/train\")\nVAL_LABEL_DIR = os.path.join(YOLO_DATASET_DIR, \"labels/val\")\nDATA_YAML_PATH = os.path.join(YOLO_DATASET_DIR, \"data.yaml\")\n\n# --- Data Preparation Parameters ---\n# !! CRITICAL: Define your class mapping !!\n# Map LISA annotation tags (lowercase) to YOLO class IDs (0, 1, 2...).\n# VERIFY these tags against the unique values in the 'Annotation tag' column of your CSV!\nCLASS_MAPPING = {\n    'stop': 0,\n    'stopleft': 0,  # Map to 'stop'\n    'warning': 1,\n    'warningleft': 1, # Map to 'warning'\n    'go': 2,\n    'goleft': 2,    # Map to 'go'\n    'goforward': 2, # Map to 'go'\n    # Add 'off' or others if they appear and you need them\n}\n\nprint(f\"Using Class Mapping: {CLASS_MAPPING}\")\n\nVALIDATION_SPLIT_SIZE = 0.20 # 20% of data for validation\nRANDOM_STATE_SPLIT = 42 # For reproducible train/val splits\n\n# --- YOLOv8 Training Parameters ---\nMODEL_CHOICE = 'yolov8n.pt' # Nano version - good for edge devices (Raspberry Pi/Jetson)\nEPOCHS = 75 # Start with 50-100, adjust based on results\nIMG_SIZE = 640\nBATCH_SIZE = 32 # Adjust based on T4 memory (16/32 common for 2xT4) - If CUDA OOM, reduce this!\nPATIENCE_EPOCHS = 15 # Early stopping patience\nOPTIMIZER = 'AdamW' # Or 'SGD', 'Adam'\nLEARNING_RATE = 0.001 # Example LR, can tune this (YOLO defaults are often good)\nNUM_WORKERS = 2 # Kaggle typically has 2 CPU cores available\n\nPROJECT_NAME = 'LISA_Traffic_Light_Detection'\nRUN_NAME = f'{MODEL_CHOICE.split(\".\")[0]}_e{EPOCHS}_bs{BATCH_SIZE}_{time.strftime(\"%Y%m%d_%H%M%S\")}'\n\n# --- Device Config ---\n# Automatically use available GPUs, fallback to CPU\n# if torch.cuda.is_available():\n#     gpu_count = torch.cuda.device_count()\n#     if gpu_count >= 2:\n#         DEVICE_CONFIG = '0,1' # Use first two GPUs\n#         print(\"Configuring training for 2 GPUs (0, 1).\")\n#     elif gpu_count == 1:\n#         DEVICE_CONFIG = '0'   # Use the single available GPU\n#         print(\"Configuring training for 1 GPU (0).\")\n#     else: # This case should ideally not happen if cuda.is_available is true, but safety first\n#          DEVICE_CONFIG = 'cpu'\n#          print(\"CUDA reported available, but no devices found? Falling back to CPU.\")\n# else:\n#     DEVICE_CONFIG = 'cpu'\n#     print(\"Configuring training for CPU.\")\n\nif torch.cuda.is_available():\n    DEVICE_CONFIG = '0' # Use only GPU 0\n    print(\"***** DEBUGGING: Forcing training on SINGLE GPU (0) *****\")\nelse:\n    DEVICE_CONFIG = 'cpu'\n    print(\"Configuring training for CPU.\")\n# ***** END MODIFICATION *****\n\nprint(f\"Training Device Setting: {DEVICE_CONFIG}\")\nprint(f\"Output dataset dir: {YOLO_DATASET_DIR}\")\nprint(\"-\" * 30)\n\nprint(f\"Training Device Setting: {DEVICE_CONFIG}\")\nprint(f\"Output dataset dir: {YOLO_DATASET_DIR}\")\nprint(\"-\" * 30)\nprint(\"--- Cell 2 finished defining variables ---\")\nprint(f\"DEBUG: MODEL_CHOICE in Cell 2 is: {MODEL_CHOICE}\") # Verify one variable","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:00:24.959173Z","iopub.execute_input":"2025-04-04T10:00:24.959451Z","iopub.status.idle":"2025-04-04T10:00:24.970260Z","shell.execute_reply.started":"2025-04-04T10:00:24.959429Z","shell.execute_reply":"2025-04-04T10:00:24.969398Z"}},"outputs":[{"name":"stdout","text":"Using Class Mapping: {'stop': 0, 'stopleft': 0, 'warning': 1, 'warningleft': 1, 'go': 2, 'goleft': 2, 'goforward': 2}\n***** DEBUGGING: Forcing training on SINGLE GPU (0) *****\nTraining Device Setting: 0\nOutput dataset dir: /kaggle/working/lisa_yolo_format\n------------------------------\nTraining Device Setting: 0\nOutput dataset dir: /kaggle/working/lisa_yolo_format\n------------------------------\n--- Cell 2 finished defining variables ---\nDEBUG: MODEL_CHOICE in Cell 2 is: yolov8n.pt\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(MODEL_CHOICE)\nprint(DATA_YAML_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:00:27.409063Z","iopub.execute_input":"2025-04-04T10:00:27.409343Z","iopub.status.idle":"2025-04-04T10:00:27.413648Z","shell.execute_reply.started":"2025-04-04T10:00:27.409323Z","shell.execute_reply":"2025-04-04T10:00:27.412626Z"}},"outputs":[{"name":"stdout","text":"yolov8n.pt\n/kaggle/working/lisa_yolo_format/data.yaml\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import glob # Import glob for finding files\nimport os\nimport pandas as pd\nimport cv2\nfrom tqdm.notebook import tqdm # Use notebook-friendly tqdm\nimport sys\n\nprint(\"--- Starting Annotation Conversion (CSV to YOLO .txt) ---\")\n\n# --- Create Output Directories ---\n# (Directories should exist from previous run, exist_ok=True handles it)\nos.makedirs(OUTPUT_LABELS_DIR, exist_ok=True)\nos.makedirs(TRAIN_IMG_DIR, exist_ok=True)\nos.makedirs(VAL_IMG_DIR, exist_ok=True)\nos.makedirs(TRAIN_LABEL_DIR, exist_ok=True)\nos.makedirs(VAL_LABEL_DIR, exist_ok=True)\nprint(f\"Ensured output directories exist inside: {YOLO_DATASET_DIR}\")\n\n# --- Find all relevant Annotation CSV files ---\nsearch_pattern = os.path.join(ANNOTATIONS_DIR, 'Annotations', '*', 'frameAnnotationsBOX.csv')\nprint(f\"Searching for annotation files using pattern: {search_pattern}\")\ncsv_files = glob.glob(search_pattern)\n\nif not csv_files:\n    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(f\"ERROR: No 'frameAnnotationsBOX.csv' files found using pattern: {search_pattern}\")\n    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    sys.exit(\"No annotation CSV files found. Stopping.\")\nelse:\n    print(f\"Found {len(csv_files)} annotation CSV files to process.\")\n\n# --- Load and Combine Annotations ---\nall_annotations_list = []\nprint(\"Loading and combining annotations...\")\nfor csv_path in tqdm(csv_files, desc=\"Reading CSVs\"):\n    try:\n        sequence_name = os.path.basename(os.path.dirname(csv_path))\n        temp_df = pd.read_csv(csv_path, delimiter=';')\n        temp_df['sequence'] = sequence_name\n        temp_df['csv_source'] = csv_path\n        all_annotations_list.append(temp_df)\n    except Exception as e:\n        print(f\"\\nWARNING: Failed to load or parse CSV file '{csv_path}': {e}. Skipping.\")\n\nif not all_annotations_list:\n     print(\"ERROR: Failed to load data from any CSV file. Stopping.\")\n     sys.exit(\"No annotation data loaded.\")\n\ndf = pd.concat(all_annotations_list, ignore_index=True)\nprint(f\"Combined {len(df)} total annotation entries from {len(csv_files)} files.\")\n\n# --- Display Combined CSV Info ---\n# print(\"\\nFirst 5 rows of the combined annotation data:\") # Optional: uncomment to view\n# print(df.head())\nprint(\"\\nUnique values in 'Annotation tag' column:\")\nif 'Annotation tag' in df.columns:\n    print(df['Annotation tag'].dropna().unique())\nelse:\n    print(\"'Annotation tag' column not found!\")\nprint(\"\\nColumns found in combined data:\", df.columns.tolist())\nprint(\"-\" * 30)\n\n# --- Verify Required Columns (Adjust names if needed based on printout above!) ---\nrequired_cols = ['Filename', 'Annotation tag', 'Upper left corner X', 'Upper left corner Y', 'Lower right corner X', 'Lower right corner Y', 'sequence']\nif not all(col in df.columns for col in required_cols):\n    print(f\"ERROR: Missing one or more required columns in the combined CSV data!\")\n    print(f\"Script Requires: {required_cols}. Found: {df.columns.tolist()}\")\n    sys.exit(\"Missing required columns in combined CSV data. Stopping.\")\nprint(\"Required columns found in combined data.\")\n\n# --- Conversion Process ---\nconversion_errors = 0\nfiles_processed_map = {} # Track files {img_basename: [yolo_line, ...]}\nannotations_converted_count = 0\nskipped_classes = set()\nprocessed_image_paths = {} # Store mapping {img_basename: {'path': str, 'h': int, 'w': int}}\n\nprint(f\"Processing {len(df)} annotation entries...\")\n\n# Iterate through rows of the combined dataframe\nfor index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Converting Annotations\"):\n\n    sequence_name = row['sequence'] # e.g., 'daySequence1'\n    filename_in_csv = row['Filename'] # e.g., 'dayTest/daySequence1--00111.jpg'\n\n    # --- *** CORRECTED Image Path Construction *** ---\n    # Extract the actual filename part (e.g., daySequence1--00111.jpg)\n    actual_image_filename = os.path.basename(filename_in_csv)\n    # Construct the path based on observed structure: base/seq/seq/frames/actual_file.jpg\n    image_path = os.path.normpath(os.path.join(LISA_IMAGES_BASE_DIR, sequence_name, sequence_name, 'frames', actual_image_filename))\n    # --- ***************************************** ---\n\n    # Get image basename (e.g., 'daySequence1--00111') - Use this as the key\n    image_basename = os.path.splitext(actual_image_filename)[0]\n\n    # Get image dimensions (read only once per image)\n    if image_basename not in processed_image_paths:\n        if not os.path.isfile(image_path):\n            # This is now the expected failure point if path logic is still wrong\n            # print(f\"\\nDEBUG: Image file not found at constructed path: '{image_path}' (derived from seq='{sequence_name}', csv_filename='{filename_in_csv}')\")\n            conversion_errors += 1\n            # Store None to avoid re-checking this failed path\n            processed_image_paths[image_basename] = {'path': None, 'h': None, 'w': None}\n            continue # Skip this annotation if image doesn't exist at constructed path\n\n        # Try reading the image only if path exists\n        try:\n            img = cv2.imread(image_path)\n            if img is None:\n                print(f\"\\nWarning: Found but failed to read image '{image_path}'. Skipping annotations for it.\")\n                conversion_errors += 1\n                processed_image_paths[image_basename] = {'path': image_path, 'h': None, 'w': None}\n                continue\n            img_height, img_width, _ = img.shape\n            if img_height == 0 or img_width == 0:\n                 print(f\"\\nWarning: Invalid image dimensions (0) for '{image_path}'. Skipping.\")\n                 conversion_errors += 1\n                 processed_image_paths[image_basename] = {'path': image_path, 'h': None, 'w': None}\n                 continue\n            # Store path and dimensions upon successful read\n            processed_image_paths[image_basename] = {'path': image_path, 'h': img_height, 'w': img_width}\n\n        except Exception as e:\n            print(f\"\\nERROR reading image '{image_path}': {e}\")\n            conversion_errors += 1\n            processed_image_paths[image_basename] = {'path': image_path, 'h': None, 'w': None}\n            continue\n    # End if image_basename not in processed_image_paths\n\n    # Retrieve stored data\n    img_data = processed_image_paths[image_basename]\n    img_height = img_data['h']\n    img_width = img_data['w']\n\n    # Skip if we failed to get dimensions or path earlier\n    if img_data['path'] is None or img_height is None or img_width is None:\n        continue\n\n    # --- Process the annotation for this row (Class Mapping) ---\n    class_label = str(row['Annotation tag']).lower().strip()\n\n    # Use the CLASS_MAPPING defined in Cell 2\n    if class_label not in CLASS_MAPPING:\n        if class_label not in skipped_classes:\n            # print(f\"\\nInfo: Skipping unrecognized class label '{class_label}' (in {row['csv_source']} for {filename_in_csv}). Update CLASS_MAPPING in Cell 2 if needed.\")\n            skipped_classes.add(class_label)\n        continue # Skip if class not in our defined mapping\n\n    class_id = CLASS_MAPPING[class_label]\n\n    # Get bounding box coordinates\n    try:\n        x1 = int(row['Upper left corner X'])\n        y1 = int(row['Upper left corner Y'])\n        x2 = int(row['Lower right corner X'])\n        y2 = int(row['Lower right corner Y'])\n    except ValueError as ve:\n        # print(f\"\\nWarning: Invalid coordinate value for '{class_label}' in {row['csv_source']} for {filename_in_csv}: {ve}. Skipping box.\")\n        conversion_errors += 1\n        continue\n\n    # Coordinate Validation (same as before)\n    valid_coords = True\n    if x1 >= x2 or y1 >= y2 or x1 < 0 or y1 < 0 or x2 > img_width or y2 > img_height:\n        valid_coords = False; conversion_errors += 1\n    if not valid_coords:\n        continue\n\n    # Convert to YOLO format (same as before)\n    box_width = float(x2 - x1); box_height = float(y2 - y1)\n    center_x = float(x1) + box_width / 2; center_y = float(y1) + box_height / 2\n    norm_center_x = round(center_x / img_width, 6); norm_center_y = round(center_y / img_height, 6)\n    norm_width = round(box_width / img_width, 6); norm_height = round(box_height / img_height, 6)\n    norm_center_x = max(0.0, min(1.0, norm_center_x)); norm_center_y = max(0.0, min(1.0, norm_center_y))\n    norm_width    = max(0.0, min(1.0, norm_width)); norm_height   = max(0.0, min(1.0, norm_height))\n    if norm_width <= 0 or norm_height <= 0:\n        conversion_errors += 1; continue\n\n    # Add annotation line to the map for this image basename\n    if image_basename not in files_processed_map:\n        files_processed_map[image_basename] = []\n    files_processed_map[image_basename].append(f\"{class_id} {norm_center_x} {norm_center_y} {norm_width} {norm_height}\")\n    annotations_converted_count += 1\n\n\n# --- Write YOLO .txt files ---\nprint(f\"\\nWriting YOLO label files to {OUTPUT_LABELS_DIR}...\")\nlabels_written_count = 0\n# Filter map to only include entries where annotations were successfully generated\nvalid_entries_for_writing = {k: v for k, v in files_processed_map.items() if v}\nprint(f\"Attempting to write {len(valid_entries_for_writing)} label files.\")\n\nfor img_basename, yolo_lines in tqdm(valid_entries_for_writing.items(), desc=\"Writing Label Files\"):\n    label_filename = f\"{img_basename}.txt\"\n    label_path = os.path.join(OUTPUT_LABELS_DIR, label_filename)\n    try:\n        with open(label_path, 'w') as f:\n            f.write(\"\\n\".join(yolo_lines) + \"\\n\")\n        labels_written_count += 1\n    except Exception as e:\n        print(f\"\\nERROR: Failed to write label file '{label_path}': {e}\")\n        conversion_errors += 1\n\n\n# --- Final Conversion Summary ---\nprint(\"\\n--- Annotation Conversion Summary ---\")\n# Count how many images were successfully read (had dimensions)\nsuccessful_reads = sum(1 for data in processed_image_paths.values() if data['h'] is not None)\nprint(f\"Images processed (found file and read dimensions): {successful_reads}\")\nprint(f\"Total unique image basenames encountered: {len(processed_image_paths)}\")\nprint(f\"Annotations converted successfully (associated with a read image): {annotations_converted_count}\")\nprint(f\"YOLO label files written: {labels_written_count} (to {OUTPUT_LABELS_DIR})\")\nif skipped_classes:\n    print(f\"Skipped unrecognized classes (Check CLASS_MAPPING in Cell 2): {list(skipped_classes)}\")\n# Recalculate errors more accurately: Total annotations - successful conversions\ntotal_possible_conversions = len(df) # Number of rows we tried to process\nfinal_error_count = total_possible_conversions - annotations_converted_count\nprint(f\"Encountered approx {final_error_count} warnings/errors (incl. missing images, bad coords/reads, skipped classes, write errors).\")\nprint(\"--- Annotation Conversion Finished ---\")\nprint(\"-\" * 30)\n\n# --- Update processed_image_paths for Train/Val Split ---\n# We need a simple map from basename -> full image path for the next cell\n# Ensure we only include paths for images that were successfully processed\nimage_path_mapping_for_split = {basename: data['path']\n                                for basename, data in processed_image_paths.items()\n                                if data['path'] is not None and data['h'] is not None}\nprint(f\"Created image path map with {len(image_path_mapping_for_split)} entries for Train/Val split.\")\nif len(image_path_mapping_for_split) == 0 and labels_written_count > 0:\n    print(\"\\nCRITICAL WARNING: Label files were written, but the image path map for splitting is empty. Check logic.\")\nelif len(image_path_mapping_for_split) == 0:\n     print(\"\\nWARNING: No images were successfully processed. Train/Val split will likely fail.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T20:24:06.651145Z","iopub.execute_input":"2025-04-03T20:24:06.651505Z","iopub.status.idle":"2025-04-03T20:25:57.793016Z","shell.execute_reply.started":"2025-04-03T20:24:06.651476Z","shell.execute_reply":"2025-04-03T20:25:57.792229Z"}},"outputs":[{"name":"stdout","text":"--- Starting Annotation Conversion (CSV to YOLO .txt) ---\nEnsured output directories exist inside: /kaggle/working/lisa_yolo_format\nSearching for annotation files using pattern: /kaggle/working/lisa_traffic_light/Annotations/Annotations/*/frameAnnotationsBOX.csv\nFound 4 annotation CSV files to process.\nLoading and combining annotations...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Reading CSVs:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67de96d842e24b6eb0b5822cd0c42e24"}},"metadata":{}},{"name":"stdout","text":"Combined 57649 total annotation entries from 4 files.\n\nUnique values in 'Annotation tag' column:\n['go' 'stop' 'warning' 'stopLeft' 'goLeft' 'warningLeft' 'goForward']\n\nColumns found in combined data: ['Filename', 'Annotation tag', 'Upper left corner X', 'Upper left corner Y', 'Lower right corner X', 'Lower right corner Y', 'Origin file', 'Origin frame number', 'Origin track', 'Origin track frame number', 'sequence', 'csv_source']\n------------------------------\nRequired columns found in combined data.\nProcessing 57649 annotation entries...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Converting Annotations:   0%|          | 0/57649 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"729c402677fb4daf9d4828c5b5c5ac28"}},"metadata":{}},{"name":"stdout","text":"\nWriting YOLO label files to /kaggle/working/lisa_yolo_format/raw_labels...\nAttempting to write 18252 label files.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Writing Label Files:   0%|          | 0/18252 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae37d0b9752449b18de8b4c4f31070ce"}},"metadata":{}},{"name":"stdout","text":"\n--- Annotation Conversion Summary ---\nImages processed (found file and read dimensions): 18252\nTotal unique image basenames encountered: 18252\nAnnotations converted successfully (associated with a read image): 57649\nYOLO label files written: 18252 (to /kaggle/working/lisa_yolo_format/raw_labels)\nEncountered approx 0 warnings/errors (incl. missing images, bad coords/reads, skipped classes, write errors).\n--- Annotation Conversion Finished ---\n------------------------------\nCreated image path map with 18252 entries for Train/Val split.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import os\nimport shutil\nimport sys\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\n\nprint(\"--- Starting Train/Validation Split ---\")\n\n# Get list of image basenames for which we generated labels\n# Make sure 'image_path_mapping_for_split' exists from the end of Cell 3\nif 'image_path_mapping_for_split' not in locals() or not isinstance(image_path_mapping_for_split, dict):\n     print(\"ERROR: 'image_path_mapping_for_split' dictionary not found or is not a dictionary.\")\n     print(\"Please ensure Cell 3 ran correctly and created this variable.\")\n     sys.exit(\"Aborting split due to missing input map.\")\n\nvalid_basenames = list(image_path_mapping_for_split.keys()) # Use the corrected map from Cell 3\nprint(f\"Found {len(valid_basenames)} images with corresponding annotations to split.\")\n\nif not valid_basenames:\n    print(\"ERROR: No valid image basenames found in the map from Cell 3. Cannot proceed.\")\n    sys.exit(\"Aborting due to lack of processable data.\")\n\n# Split the basenames\ntry:\n    train_basenames, val_basenames = train_test_split(\n        valid_basenames,\n        test_size=VALIDATION_SPLIT_SIZE, # Defined in Cell 2\n        random_state=RANDOM_STATE_SPLIT  # Defined in Cell 2\n    )\nexcept Exception as e:\n     print(f\"ERROR during train_test_split: {e}\")\n     sys.exit(\"Aborting split.\")\n\nprint(f\"Splitting into: {len(train_basenames)} Train / {len(val_basenames)} Validation images\")\n\n# --- Function to copy files ---\ndef copy_files(basenames, source_img_path_map, source_label_dir, dest_img_dir, dest_label_dir):\n    copied_count = 0\n    error_count = 0\n    print(f\"Copying files to {dest_img_dir} and {dest_label_dir}...\")\n    for basename in tqdm(basenames, desc=f\"Copying to {os.path.basename(dest_img_dir)}\"):\n        # Get the actual image source path from the map created in Cell 3\n        img_src_path = source_img_path_map.get(basename) # This should now be a string path\n        label_src_path = os.path.join(source_label_dir, f\"{basename}.txt\")\n\n        # --- *** CORRECTED LOGIC *** ---\n        if img_src_path and os.path.exists(label_src_path):\n            # Now img_src_path should be a string, directly usable\n            if not isinstance(img_src_path, str):\n                 print(f\"\\nWarning: Expected string path for basename '{basename}', but got {type(img_src_path)}. Skipping.\")\n                 error_count += 1\n                 continue\n\n            img_filename = os.path.basename(img_src_path) # Get filename from the string path\n            label_filename = f\"{basename}.txt\"          # Label filename uses basename\n\n            img_dest_path = os.path.join(dest_img_dir, img_filename)\n            label_dest_path = os.path.join(dest_label_dir, label_filename)\n\n            try:\n                # Ensure source image file exists before copying\n                if not os.path.isfile(img_src_path):\n                     print(f\"\\nWarning: Source image file confirmed missing at '{img_src_path}' for basename '{basename}'. Skipping copy.\")\n                     error_count +=1\n                     continue\n\n                shutil.copy2(img_src_path, img_dest_path) # copy2 preserves metadata\n                shutil.copy2(label_src_path, label_dest_path)\n                copied_count += 1\n            except Exception as e:\n                print(f\"\\nError copying files for basename '{basename}' (Image: '{img_src_path}', Label: '{label_src_path}'): {e}\")\n                error_count += 1\n        # --- ************************* ---\n        else:\n             # Log reasons for skipping\n             if not img_src_path:\n                 print(f\"\\nWarning: Image source path not found in map for basename '{basename}'. Cannot copy.\")\n             elif not os.path.exists(label_src_path):\n                  print(f\"\\nWarning: Label file not found at '{label_src_path}' for basename '{basename}'. Cannot copy image either.\")\n             # Increment error count if either is missing\n             error_count += 1\n             \n    print(f\"Finished copying. Copied: {copied_count}, Errors/Skipped: {error_count}\")\n    return copied_count\n\n# --- Copy Training Files ---\n# Use the 'image_path_mapping_for_split' dictionary created at the end of Cell 3\ntrain_copied = copy_files(train_basenames, image_path_mapping_for_split, OUTPUT_LABELS_DIR, TRAIN_IMG_DIR, TRAIN_LABEL_DIR)\n\n# --- Copy Validation Files ---\nval_copied = copy_files(val_basenames, image_path_mapping_for_split, OUTPUT_LABELS_DIR, VAL_IMG_DIR, VAL_LABEL_DIR)\n\n# --- Split Summary ---\nprint(\"\\n--- Train/Validation Split Summary ---\")\nprint(f\"Total images intended for train: {len(train_basenames)}, Copied successfully: {train_copied}\")\nprint(f\"Total images intended for val:   {len(val_basenames)}, Copied successfully: {val_copied}\")\n# Check if the number of successfully copied files matches the intended number\ntrain_errors = len(train_basenames) - train_copied\nval_errors = len(val_basenames) - val_copied\nif train_errors > 0 or val_errors > 0:\n     print(f\"Warning: {train_errors} training files and {val_errors} validation files were NOT copied successfully. Check warnings above.\")\nprint(f\"Training images copied to:   {TRAIN_IMG_DIR}\")\nprint(f\"Training labels copied to:   {TRAIN_LABEL_DIR}\")\nprint(f\"Validation images copied to: {VAL_IMG_DIR}\")\nprint(f\"Validation labels copied to: {VAL_LABEL_DIR}\")\nprint(\"--- Train/Validation Split Finished ---\")\nprint(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T20:29:21.021376Z","iopub.execute_input":"2025-04-03T20:29:21.021729Z","iopub.status.idle":"2025-04-03T20:29:27.051052Z","shell.execute_reply.started":"2025-04-03T20:29:21.021699Z","shell.execute_reply":"2025-04-03T20:29:27.050169Z"}},"outputs":[{"name":"stdout","text":"--- Starting Train/Validation Split ---\nFound 18252 images with corresponding annotations to split.\nSplitting into: 14601 Train / 3651 Validation images\nCopying files to /kaggle/working/lisa_yolo_format/images/train and /kaggle/working/lisa_yolo_format/labels/train...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Copying to train:   0%|          | 0/14601 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807030d94f0541bb8f35e1a29cfb4ee1"}},"metadata":{}},{"name":"stdout","text":"Finished copying. Copied: 14601, Errors/Skipped: 0\nCopying files to /kaggle/working/lisa_yolo_format/images/val and /kaggle/working/lisa_yolo_format/labels/val...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Copying to val:   0%|          | 0/3651 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e9723e26f0c443ca463a61a094a366e"}},"metadata":{}},{"name":"stdout","text":"Finished copying. Copied: 3651, Errors/Skipped: 0\n\n--- Train/Validation Split Summary ---\nTotal images intended for train: 14601, Copied successfully: 14601\nTotal images intended for val:   3651, Copied successfully: 3651\nTraining images copied to:   /kaggle/working/lisa_yolo_format/images/train\nTraining labels copied to:   /kaggle/working/lisa_yolo_format/labels/train\nValidation images copied to: /kaggle/working/lisa_yolo_format/images/val\nValidation labels copied to: /kaggle/working/lisa_yolo_format/labels/val\n--- Train/Validation Split Finished ---\n------------------------------\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(\"--- Creating data.yaml ---\")\n\n# --- Get Class Names in Order ---\n# Sort the CLASS_MAPPING by ID (0, 1, 2...) to ensure correct order in YAML\nsorted_class_items = sorted(CLASS_MAPPING.items(), key=lambda item: item[1])\nclass_names = [item[0] for item in sorted_class_items]\nnum_classes = len(class_names)\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Class names (in order): {class_names}\")\n\n# --- Create YAML Data Structure ---\nyaml_data = {\n    'train': TRAIN_IMG_DIR,\n    'val': VAL_IMG_DIR,\n    'nc': num_classes,\n    'names': class_names\n}\n\n# --- Write YAML File ---\ntry:\n    with open(DATA_YAML_PATH, 'w') as f:\n        yaml.dump(yaml_data, f, sort_keys=False) # sort_keys=False preserves order\n    print(f\"Successfully created data.yaml at: {DATA_YAML_PATH}\")\n    # --- Print YAML content for verification ---\n    print(\"\\n--- data.yaml content: ---\")\n    with open(DATA_YAML_PATH, 'r') as f:\n        print(f.read())\n    print(\"--------------------------\")\nexcept Exception as e:\n    print(f\"ERROR: Failed to write data.yaml file: {e}\")\n    sys.exit(\"Aborting due to YAML write error.\")\n\nprint(\"--- data.yaml Creation Finished ---\")\nprint(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T20:30:11.773389Z","iopub.execute_input":"2025-04-03T20:30:11.773726Z","iopub.status.idle":"2025-04-03T20:30:11.782834Z","shell.execute_reply.started":"2025-04-03T20:30:11.773697Z","shell.execute_reply":"2025-04-03T20:30:11.782184Z"}},"outputs":[{"name":"stdout","text":"--- Creating data.yaml ---\nNumber of classes: 7\nClass names (in order): ['stop', 'stopleft', 'warning', 'warningleft', 'go', 'goleft', 'goforward']\nSuccessfully created data.yaml at: /kaggle/working/lisa_yolo_format/data.yaml\n\n--- data.yaml content: ---\ntrain: /kaggle/working/lisa_yolo_format/images/train\nval: /kaggle/working/lisa_yolo_format/images/val\nnc: 7\nnames:\n- stop\n- stopleft\n- warning\n- warningleft\n- go\n- goleft\n- goforward\n\n--------------------------\n--- data.yaml Creation Finished ---\n------------------------------\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# --- Imports for Cell 7 ---\nimport time\nimport sys\nimport os\nimport glob\nfrom IPython.display import Image, display\nfrom ultralytics import YOLO\nimport torch\nimport traceback\n# --- End Imports ---\n\nprint(\"--- Cell 7 Starting ---\")\n# --- Variable Existence Check (Alternative Method) ---\nprint(\"DEBUG: Checking required variables individually...\")\nvariables_ok = True\nrequired_vars_list = ['MODEL_CHOICE', 'DATA_YAML_PATH', 'EPOCHS', 'BATCH_SIZE', 'IMG_SIZE',\n                      'DEVICE_CONFIG', 'PROJECT_NAME', 'RUN_NAME', 'BASE_DIR',\n                      'PATIENCE_EPOCHS', 'NUM_WORKERS', 'OPTIMIZER', 'LEARNING_RATE']\nmissing_vars_details = []\n\nfor var_name in required_vars_list:\n    # Check if the variable exists in either the local or global scope\n    if var_name not in locals() and var_name not in globals():\n        print(f\"DEBUG: Variable '{var_name}' NOT FOUND.\")\n        missing_vars_details.append(var_name)\n        variables_ok = False\n    # else: # Optional: uncomment to confirm variables are found\n    #     print(f\"DEBUG: Variable '{var_name}' found.\")\n\nif not variables_ok:\n    print(f\"ERROR: The following configuration variables are not defined: {missing_vars_details}\")\n    print(\"Please ensure Cell 2 (Configuration) was run successfully before this cell.\")\n    sys.exit(\"Aborting training due to missing config variables.\")\nelse:\n     print(\"DEBUG: All required variables confirmed present.\")\n# --- End Variable Check ---\n\nprint(\"\\n--- Starting YOLOv8 Training ---\") # Add newline for clarity\n\n# --- Print Configuration (Now that variables are confirmed) ---\nprint(f\"Model: {MODEL_CHOICE}\")\nprint(f\"Dataset Config: {DATA_YAML_PATH}\")\nprint(f\"Epochs: {EPOCHS}, Batch Size: {BATCH_SIZE}, Image Size: {IMG_SIZE}\")\nprint(f\"Device: {DEVICE_CONFIG}\")\nprint(f\"Project: {PROJECT_NAME}, Run Name: {RUN_NAME}\")\nprint(f\"Patience: {PATIENCE_EPOCHS}, Workers: {NUM_WORKERS}, Optimizer: {OPTIMIZER}, LR: {LEARNING_RATE}\")\n# Construct full results path for clarity\nresults_dir = os.path.join(BASE_DIR, PROJECT_NAME, RUN_NAME)\nprint(f\"Output will be saved to: {results_dir}\")\n\n# --- W&B Status (Variable defined in Cell 6) ---\nif 'wandb_enabled' not in locals():\n     wandb_enabled = False # Assume disabled if Cell 6 wasn't run or failed\n     print(\"W&B status unknown (assuming DISABLED).\")\nelif wandb_enabled:\n    print(\"Weights & Biases logging is ENABLED.\")\nelse:\n    print(\"Weights & Biases logging is DISABLED.\")\nprint(\"-\" * 30)\n\nos.environ['NCCL_DEBUG'] = 'INFO' # Get more verbose output from NCCL (helps debugging if it hangs)\nos.environ['NCCL_SOCKET_IFNAME'] = 'eth0' # Sometimes needed in Docker - Kaggle usually uses 'eth0'\nprint(\"DEBUG: Set NCCL_DEBUG=INFO and NCCL_SOCKET_IFNAME=eth0\")\n\n# --- Load Model ---\ntry:\n    model = YOLO(MODEL_CHOICE) # Load pretrained weights\n    print(f\"Loaded model '{MODEL_CHOICE}' successfully.\")\nexcept Exception as e:\n    print(f\"ERROR: Failed to load YOLO model: {e}\")\n    sys.exit(\"Aborting training.\")\n\n\n# --- Start Training ---\nstart_time = time.time()\ntraining_successful = False\nprint(\"\\n--- Initiating model.train() ---\")\nprint(\"Training progress (loss, metrics per epoch) will be printed below by Ultralytics:\")\nprint(\"-\" * 60)\ntry:\n    # The train function handles multi-GPU and W&B integration automatically\n    # It will print epoch, loss, mAP, etc. automatically to the output\n    results = model.train(\n        data=DATA_YAML_PATH,\n        epochs=EPOCHS,\n        imgsz=IMG_SIZE,\n        batch=BATCH_SIZE,\n        device=DEVICE_CONFIG,\n        project=os.path.join(BASE_DIR, PROJECT_NAME), # Save results inside /kaggle/working/\n        name=RUN_NAME,\n        patience=PATIENCE_EPOCHS,\n        workers=NUM_WORKERS,\n        optimizer=OPTIMIZER,\n        lr0=LEARNING_RATE,\n        # exist_ok=False, # Prevent overwriting existing runs by default\n        # val=True, # Validate after each epoch (default)\n        # save=True, # Save checkpoints (default)\n    )\n    print(\"-\" * 60)\n    print(\"\\n--- model.train() Completed ---\")\n    training_successful = True\n\nexcept Exception as e:\n    print(\"-\" * 60)\n    print(f\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    print(f\"ERROR: An exception occurred during YOLOv8 training:\")\n    traceback.print_exc() # Print detailed traceback\n    print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n    training_successful = False # Ensure it's marked as failed\n\nexcept KeyboardInterrupt: # Handle manual interruption (e.g., pressing stop button)\n     print(\"-\" * 60)\n     print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n     print(\"KeyboardInterrupt: Training stopped manually.\")\n     print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n     training_successful = False # Mark as incomplete\n\n\n# --- Training Summary & Visualization ---\nend_time = time.time()\nduration = end_time - start_time\nprint(f\"\\n--- Training Attempt Finished ---\")\nprint(f\"Total time elapsed for this attempt: {duration:.2f} seconds\")\n\nif training_successful:\n    print(f\"\\n✅ Training completed successfully.\")\n    print(\"\\nTraining results (model weights, logs, plots) saved in:\")\n    # results_dir was defined earlier\n    best_model_path = os.path.join(results_dir, 'weights', 'best.pt')\n    print(f\" -> Directory: '{results_dir}'\")\n    print(f\" -> Best model weights (for inference/deployment): '{best_model_path}'\")\n    if os.path.exists(best_model_path):\n         print(\"   (Best model file confirmed to exist)\")\n    else:\n         print(\"   (Warning: Best model file 'best.pt' not found in expected location - check logs)\")\n\n    # --- *** INTEGRATED VISUALIZATION *** ---\n    print(\"\\n--- Displaying Training Results Visualizations ---\")\n    print(f\"Looking for plots in: {results_dir}\")\n\n    plot_files = {\n        \"Results (Loss & Metrics)\": os.path.join(results_dir, \"results.png\"),\n        \"Confusion Matrix\": os.path.join(results_dir, \"confusion_matrix.png\"),\n        \"Precision-Recall Curve\": os.path.join(results_dir, \"PR_curve.png\"),\n        \"Precision Curve\": os.path.join(results_dir, \"P_curve.png\"),\n        \"Recall Curve\": os.path.join(results_dir, \"R_curve.png\"),\n        \"F1 Curve\": os.path.join(results_dir, \"F1_curve.png\"),\n    }\n\n    found_plots = False\n    for plot_name, plot_path in plot_files.items():\n        if os.path.exists(plot_path):\n            print(f\"\\n-> {plot_name}:\")\n            try:\n                display(Image(filename=plot_path, width=800)) # Adjust width as needed\n                found_plots = True\n            except Exception as img_e:\n                 print(f\"   Error displaying image '{plot_path}': {img_e}\")\n        else:\n            print(f\"   Plot not found: {os.path.basename(plot_path)}\") # Print only filename if not found\n\n    if not found_plots:\n         print(\"\\nCould not find standard plot files (results.png, etc.) in the results directory.\")\n\n    # Display sample validation predictions if available\n    val_batch_labels = sorted(glob.glob(os.path.join(results_dir, \"val_batch*_labels.jpg\")))\n    val_batch_preds = sorted(glob.glob(os.path.join(results_dir, \"val_batch*_pred.jpg\")))\n\n    if val_batch_labels and val_batch_preds:\n         print(\"\\n-> Sample Validation Batch Predictions (Batch 0):\")\n         try:\n             print(\"   Ground Truth Labels:\")\n             display(Image(filename=val_batch_labels[0], width=800))\n             print(\"   Model Predictions:\")\n             display(Image(filename=val_batch_preds[0], width=800))\n         except Exception as img_e:\n              print(f\"   Error displaying validation batch images: {img_e}\")\n    else:\n        print(\"\\nValidation batch images (val_batch*_labels.jpg / val_batch*_pred.jpg) not found.\")\n    # --- ******************************** ---\n\nelse:\n    print(f\"\\n❌ Training did not complete successfully (or was interrupted).\")\n    print(\"Results directory might be incomplete or missing.\")\n\n# --- W&B Finish (Conditional) ---\n# Check wandb_enabled again in case Cell 6 defined it differently\nif 'wandb_enabled' in locals() and wandb_enabled and training_successful:\n    print(\"\\nAttempting to finish W&B run...\")\n    try:\n         # Check if wandb was actually imported and initialized before finishing\n         if 'wandb' in sys.modules and wandb.run is not None:\n              wandb.finish()\n              print(\"W&B run finished.\")\n         else:\n              print(\"W&B run was not active, skipping finish.\")\n    except Exception as wb_e:\n         print(f\"Error finishing W&B run: {wb_e}\")\n\nprint(\"\\n--- Cell 7 Execution Finished ---\")\nprint(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T10:00:32.033121Z","iopub.execute_input":"2025-04-04T10:00:32.033438Z"}},"outputs":[{"name":"stdout","text":"--- Cell 7 Starting ---\nDEBUG: Checking required variables individually...\nDEBUG: All required variables confirmed present.\n\n--- Starting YOLOv8 Training ---\nModel: yolov8n.pt\nDataset Config: /kaggle/working/lisa_yolo_format/data.yaml\nEpochs: 75, Batch Size: 32, Image Size: 640\nDevice: 0\nProject: LISA_Traffic_Light_Detection, Run Name: yolov8n_e75_bs32_20250404_100024\nPatience: 15, Workers: 2, Optimizer: AdamW, LR: 0.001\nOutput will be saved to: /kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024\nW&B status unknown (assuming DISABLED).\n------------------------------\nDEBUG: Set NCCL_DEBUG=INFO and NCCL_SOCKET_IFNAME=eth0\nLoaded model 'yolov8n.pt' successfully.\n\n--- Initiating model.train() ---\nTraining progress (loss, metrics per epoch) will be printed below by Ultralytics:\n------------------------------------------------------------\nUltralytics 8.3.101 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/working/lisa_yolo_format/data.yaml, epochs=75, time=None, patience=15, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=2, project=/kaggle/working/LISA_Traffic_Light_Detection, name=yolov8n_e75_bs32_20250404_100024, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 755k/755k [00:00<00:00, 17.6MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=7\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \nModel summary: 129 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5.35M/5.35M [00:00<00:00, 75.3MB/s]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/lisa_yolo_format/labels/train.cache... 14601 images, 0 backgrounds, 0 corrupt: 100%|██████████| 14601/14601 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--00761.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--00762.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06367.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06373.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06375.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06379.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06380.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06382.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06383.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06385.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06393.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06395.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06396.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06400.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06401.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06403.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06405.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06407.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06408.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06409.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06411.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06413.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06414.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06415.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06416.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06417.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06418.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06419.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06420.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06421.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06423.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06425.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06426.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06427.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06428.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06429.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06430.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06431.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06432.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06433.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06435.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06436.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06437.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06438.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06441.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06442.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06445.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06448.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06449.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06450.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06451.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06452.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06456.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06457.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06462.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06463.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06465.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06466.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06467.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06469.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06470.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06471.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06472.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06473.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06474.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06475.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06478.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06479.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06480.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06483.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06484.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06485.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06486.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06487.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06488.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06489.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06490.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06492.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06493.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06494.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06495.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06496.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06497.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06498.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06499.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06504.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06505.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06506.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06507.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06510.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06512.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06513.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06514.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06515.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06516.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06517.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06518.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06519.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06520.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06521.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06522.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06523.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06524.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06526.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06527.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06528.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06529.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06530.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/train/nightSequence2--06532.jpg: 1 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/lisa_yolo_format/labels/val.cache... 3651 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3651/3651 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06365.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06366.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06372.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06374.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06384.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06390.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06394.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06402.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06406.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06410.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06412.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06422.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06424.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06434.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06439.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06440.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06446.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06447.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06460.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06464.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06476.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06477.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06500.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06501.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06502.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06503.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06508.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06509.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06511.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06525.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/lisa_yolo_format/images/val/nightSequence2--06531.jpg: 1 duplicate labels removed\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to /kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024\u001b[0m\nStarting training for 75 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       1/75      3.85G       1.98      1.645     0.9988         45        640: 100%|██████████| 457/457 [02:53<00:00,  2.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.84      0.416      0.468      0.211\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       2/75      4.24G      1.614     0.9188     0.9185         50        640: 100%|██████████| 457/457 [02:50<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.622      0.582      0.622      0.311\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       3/75      4.24G        1.5      0.819     0.8999         34        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.758      0.673      0.715      0.346\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       4/75      4.24G      1.427     0.7678     0.8907         27        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.788      0.705      0.772      0.371\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       5/75      4.24G      1.375     0.7171     0.8824         33        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.847      0.765      0.833      0.459\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       6/75      4.24G      1.329     0.6852     0.8757         34        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.879      0.755      0.824      0.457\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       7/75      4.24G      1.296      0.662     0.8717         26        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.869      0.784       0.85      0.461\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       8/75      4.24G      1.278     0.6542     0.8685         52        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.862      0.775      0.862      0.507\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"       9/75      4.24G       1.26     0.6317     0.8652         47        640: 100%|██████████| 457/457 [02:49<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.875      0.792      0.861      0.459\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      10/75      4.24G      1.239     0.6228     0.8616         38        640: 100%|██████████| 457/457 [02:49<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.906        0.8      0.866      0.519\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      11/75      4.24G      1.215     0.6038     0.8589         40        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.895      0.795      0.882      0.518\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      12/75      4.24G      1.202     0.6018     0.8569         62        640: 100%|██████████| 457/457 [02:48<00:00,  2.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.866      0.802      0.879      0.517\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      13/75      4.24G      1.185     0.5894     0.8535         58        640: 100%|██████████| 457/457 [02:47<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.905      0.799      0.883      0.523\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      14/75      4.24G      1.177     0.5855     0.8552         33        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.922      0.812      0.889      0.546\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      15/75      4.24G      1.167     0.5749     0.8553         45        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.903      0.811      0.888      0.537\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      16/75      4.24G      1.144     0.5663     0.8501         35        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.915      0.817      0.896      0.539\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      17/75      4.24G      1.146     0.5606     0.8512         41        640: 100%|██████████| 457/457 [02:47<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.91      0.828      0.897       0.54\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      18/75      4.24G      1.129     0.5531     0.8494         41        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.909      0.838      0.899      0.557\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      19/75      4.24G      1.124     0.5481     0.8465         53        640: 100%|██████████| 457/457 [02:46<00:00,  2.74it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.914      0.832      0.904      0.559\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      20/75      4.24G      1.113     0.5426     0.8473         53        640: 100%|██████████| 457/457 [02:50<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.915       0.82      0.902      0.563\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      21/75      4.24G      1.108     0.5424     0.8467         73        640: 100%|██████████| 457/457 [02:51<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.917      0.839      0.905      0.572\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      22/75      4.24G      1.099      0.534      0.844         38        640: 100%|██████████| 457/457 [02:50<00:00,  2.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.912      0.844      0.911      0.573\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      23/75      4.24G      1.091     0.5321     0.8435         46        640: 100%|██████████| 457/457 [02:55<00:00,  2.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.922      0.824      0.909      0.584\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      24/75      4.24G      1.081      0.524     0.8427         25        640: 100%|██████████| 457/457 [02:50<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.925      0.838      0.913      0.575\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      25/75      4.24G      1.081     0.5295     0.8412         33        640: 100%|██████████| 457/457 [02:50<00:00,  2.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.918      0.843       0.91       0.58\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      26/75      4.24G       1.07     0.5197     0.8406         41        640: 100%|██████████| 457/457 [02:50<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.923      0.846      0.914      0.584\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      27/75      4.24G      1.054     0.5103     0.8394         46        640: 100%|██████████| 457/457 [02:47<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.915      0.857      0.919      0.597\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      28/75      4.24G      1.055     0.5114     0.8371         40        640: 100%|██████████| 457/457 [02:52<00:00,  2.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.914      0.868      0.921        0.6\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      29/75      4.24G      1.047      0.505     0.8372         45        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.914       0.85       0.92      0.593\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      30/75      4.24G      1.049     0.5068     0.8386         42        640: 100%|██████████| 457/457 [02:48<00:00,  2.72it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.923      0.852       0.92        0.6\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      31/75      4.24G      1.035     0.5023      0.838         48        640: 100%|██████████| 457/457 [02:51<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.78it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.925      0.857       0.92        0.6\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      32/75      4.24G      1.038     0.5019     0.8367         48        640: 100%|██████████| 457/457 [02:50<00:00,  2.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.922      0.852      0.922      0.596\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      33/75      4.24G      1.033     0.4959     0.8356         26        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.916      0.856      0.922      0.599\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      34/75      4.24G      1.023     0.4922     0.8353         29        640: 100%|██████████| 457/457 [02:52<00:00,  2.65it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.923      0.849      0.922      0.601\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      35/75      4.24G       1.01      0.488     0.8322         46        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.919      0.867      0.928      0.608\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      36/75      4.24G      1.007     0.4836     0.8326         47        640: 100%|██████████| 457/457 [02:49<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.92      0.867      0.929       0.61\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      37/75      4.24G      1.006     0.4804     0.8318         41        640: 100%|██████████| 457/457 [02:50<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.929      0.862      0.928      0.612\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      38/75      4.24G      1.012      0.483     0.8315         40        640: 100%|██████████| 457/457 [02:48<00:00,  2.71it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.934      0.854      0.928      0.609\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      39/75      4.24G     0.9958     0.4784     0.8313         39        640: 100%|██████████| 457/457 [02:49<00:00,  2.69it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.90it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.921      0.866      0.927      0.613\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      40/75      4.24G      1.003      0.478     0.8324         56        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.92it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.922      0.865      0.927      0.614\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      41/75      4.24G     0.9916     0.4723     0.8313         33        640: 100%|██████████| 457/457 [02:50<00:00,  2.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:21<00:00,  2.73it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.918      0.864      0.926      0.614\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      42/75      4.24G     0.9949     0.4736     0.8313         51        640: 100%|██████████| 457/457 [02:56<00:00,  2.59it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.919      0.869      0.929      0.619\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      43/75      4.24G      0.981      0.469     0.8307         26        640: 100%|██████████| 457/457 [02:54<00:00,  2.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.916      0.866      0.926      0.619\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      44/75      4.24G     0.9828     0.4673     0.8299         37        640: 100%|██████████| 457/457 [02:54<00:00,  2.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.924      0.869      0.928       0.62\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      45/75      4.24G     0.9732     0.4597     0.8301         34        640: 100%|██████████| 457/457 [02:55<00:00,  2.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.922      0.871      0.928      0.622\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      46/75      4.24G     0.9716     0.4584     0.8305         28        640: 100%|██████████| 457/457 [02:55<00:00,  2.60it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.92      0.867      0.927      0.621\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      47/75      4.24G     0.9702      0.459     0.8301         34        640: 100%|██████████| 457/457 [02:55<00:00,  2.61it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.923       0.87       0.93      0.626\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      48/75      4.24G     0.9687     0.4575     0.8271         50        640: 100%|██████████| 457/457 [02:53<00:00,  2.63it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.84it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.93      0.868       0.93      0.625\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      49/75      4.24G     0.9627     0.4559     0.8263         51        640: 100%|██████████| 457/457 [02:52<00:00,  2.65it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.924      0.871       0.93      0.625\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      50/75      4.24G      0.954     0.4507     0.8283         47        640: 100%|██████████| 457/457 [02:51<00:00,  2.66it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.86it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.92      0.875       0.93      0.628\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      51/75      4.24G     0.9588     0.4513     0.8263         60        640: 100%|██████████| 457/457 [02:52<00:00,  2.65it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.928      0.869      0.931      0.628\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      52/75      4.24G     0.9487     0.4448     0.8273         57        640: 100%|██████████| 457/457 [02:51<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.925      0.873      0.932      0.628\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      53/75      4.24G     0.9441     0.4427     0.8257         42        640: 100%|██████████| 457/457 [02:47<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.93it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.926      0.873      0.933      0.628\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      54/75      4.24G      0.944     0.4457     0.8256         33        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.916      0.875      0.932      0.629\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      55/75      4.24G     0.9363     0.4407     0.8256         30        640: 100%|██████████| 457/457 [02:49<00:00,  2.70it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.919      0.875      0.933       0.63\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      56/75      4.24G     0.9286     0.4383     0.8246         35        640: 100%|██████████| 457/457 [02:51<00:00,  2.66it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.918      0.878      0.934       0.63\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      57/75      4.24G     0.9302     0.4371     0.8232         41        640: 100%|██████████| 457/457 [02:51<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.76it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.921      0.876      0.934      0.631\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      58/75      4.24G     0.9295      0.434     0.8236         66        640: 100%|██████████| 457/457 [02:51<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.79it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.927      0.874      0.934      0.632\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      59/75      4.24G     0.9301     0.4356     0.8251         40        640: 100%|██████████| 457/457 [02:50<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.928      0.876      0.934      0.632\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      60/75      4.24G     0.9241     0.4335     0.8247         32        640: 100%|██████████| 457/457 [02:51<00:00,  2.66it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.81it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.925      0.875      0.934      0.632\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      61/75      4.24G     0.9229     0.4312     0.8235         27        640: 100%|██████████| 457/457 [02:51<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.82it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.924      0.875      0.933      0.633\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      62/75      4.24G     0.9183     0.4296     0.8233         47        640: 100%|██████████| 457/457 [02:50<00:00,  2.68it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.924      0.874      0.934      0.634\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      63/75      4.24G     0.9124     0.4251     0.8234         37        640: 100%|██████████| 457/457 [02:52<00:00,  2.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.923      0.875      0.933      0.635\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      64/75      4.24G     0.9071     0.4251     0.8226         40        640: 100%|██████████| 457/457 [02:52<00:00,  2.64it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.83it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.926      0.875      0.935      0.636\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      65/75      4.24G      0.908     0.4253     0.8211         36        640: 100%|██████████| 457/457 [02:50<00:00,  2.67it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.85it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.927      0.875      0.935      0.636\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      66/75      4.24G     0.8759     0.4098      0.825         27        640: 100%|██████████| 457/457 [02:47<00:00,  2.73it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.926      0.877      0.936      0.636\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      67/75      4.24G     0.8653     0.4047     0.8222         26        640: 100%|██████████| 457/457 [02:44<00:00,  2.77it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.927      0.877      0.936      0.637\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      68/75      4.24G     0.8591     0.4023     0.8225         23        640: 100%|██████████| 457/457 [02:46<00:00,  2.75it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.928      0.876      0.935      0.637\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      69/75      4.24G     0.8583     0.3998     0.8235         34        640: 100%|██████████| 457/457 [02:44<00:00,  2.77it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:21<00:00,  2.74it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.929      0.875      0.935      0.638\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      70/75      4.24G     0.8557      0.397     0.8211         28        640: 100%|██████████| 457/457 [02:43<00:00,  2.80it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.87it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.93      0.873      0.936      0.638\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      71/75      4.24G     0.8487     0.3947      0.821         25        640: 100%|██████████| 457/457 [02:44<00:00,  2.78it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.91it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.931      0.874      0.936       0.64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      72/75      4.24G     0.8451     0.3936     0.8207         23        640: 100%|██████████| 457/457 [02:46<00:00,  2.75it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:19<00:00,  2.95it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.933      0.875      0.936       0.64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      73/75      4.24G     0.8422     0.3888     0.8202         25        640: 100%|██████████| 457/457 [02:41<00:00,  2.83it/s]\n      74/75      4.24G     0.8403     0.3884     0.8194         32        640: 100%|██████████| 457/457 [02:42<00:00,  2.82it/s].85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.88it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576       0.93      0.875      0.936       0.64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"      75/75      4.24G     0.8366     0.3865     0.8198         27        640: 100%|██████████| 457/457 [02:40<00:00,  2.84it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 58/58 [00:20<00:00,  2.89it/s]","output_type":"stream"},{"name":"stdout","text":"                   all       3651      11576      0.929      0.875      0.936       0.64\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n75 epochs completed in 3.973 hours.\nOptimizer stripped from /kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024/weights/last.pt, 6.2MB\nOptimizer stripped from /kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024/weights/best.pt, 6.2MB\n\nValidating /kaggle/working/LISA_Traffic_Light_Detection/yolov8n_e75_bs32_20250404_100024/weights/best.pt...\nUltralytics 8.3.101 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 72 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  47%|████▋     | 27/58 [00:11<00:13,  2.32it/s]","output_type":"stream"}],"execution_count":null}]}